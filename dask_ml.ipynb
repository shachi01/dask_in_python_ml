{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***** In Progress *****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction\n",
    "<b> Build with Logistic Regression classifier aims to classify person with heart disease in the next 10 years.</b>\n",
    "\n",
    "### Author: Shachi Kaul\n",
    "\n",
    "\n",
    "### Data Source \n",
    "Data for this usecase can be found [here](https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset)\n",
    "    \n",
    "    \n",
    "### Dataset Description\n",
    "\n",
    "- The dataset consists of 15 variables of related aspects below:\n",
    "    - demographic: male, age\n",
    "    - behavioral: currentSmoker, cigsPerDay\n",
    "    - medical: BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose\n",
    "- Predicted variable: TenYearCHD\n",
    "    This variable refers to a person of having heart disease or not with 1 as yes and 0 as no.\n",
    "\n",
    "The aim is to identify an individual at risk of having coronary heart disease in the next 10 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Notebooks focuses on how to leverage Dask in building ML model rather the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask import dataframe \n",
    "import joblib\n",
    "import dask\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "#from dask_ml.model_selection import GridSearchCV, train_test_split, HyperbandSearchCV\n",
    "import dask_ml.model_selection as dms\n",
    "from dask.distributed import Client,progress\n",
    "from dask_ml.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Some sklearn algorithms written for execute in parallel using Joblib via njobs argument such as GridSearchCV used in this notebook. \n",
    "#### - Dask reuses this Joblib library as Joblib backend and scales out to a cluster of machines. \n",
    "#### - This notebook will showcase one of the Dask features of to parallelize grid search across cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get started with Dask Dashboard to track with the progress and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://10.220.104.115/20832/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.220.104.115:8787/status' target='_blank'>http://10.220.104.115:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>8.59 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://10.220.104.115/20832/1' processes=1 threads=2, memory=8.59 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create local cluster\n",
    "client = Client(processes=False)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.read_csv(\"heart_disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treat Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "education          105\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15% of total values are empty which is acceptable to be dropped for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.212264150943398"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isna().sum().sum() / len(df) *100).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
       "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
       "       'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: dropna, 2 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                male    age education currentSmoker cigsPerDay   BPMeds prevalentStroke prevalentHyp diabetes  totChol    sysBP    diaBP      BMI heartRate  glucose TenYearCHD\n",
       "npartitions=1                                                                                                                                                                  \n",
       "               int64  int64   float64         int64    float64  float64           int64        int64    int64  float64  float64  float64  float64   float64  float64      int64\n",
       "                 ...    ...       ...           ...        ...      ...             ...          ...      ...      ...      ...      ...      ...       ...      ...        ...\n",
       "Dask Name: dropna, 2 tasks"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = df[['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
    "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
    "       'diaBP', 'BMI', 'heartRate', 'glucose']].values\n",
    "target = df['TenYearCHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array.core.Array"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "    int64\n",
       "      ...\n",
       "Name: TenYearCHD, dtype: int64\n",
       "Dask Name: getitem, 3 tasks"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got mixture of dask DataFrames and Arrays. Specify 'convert_mixed_types=True'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1eaafec93efe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask_ml\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, blockwise, convert_mixed_types, *arrays, **options)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             raise TypeError(\n\u001b[1;32m--> 446\u001b[1;33m                 \u001b[1;34m\"Got mixture of dask DataFrames and Arrays. Specify \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m                 \u001b[1;34m\"'convert_mixed_types=True'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             )\n",
      "\u001b[1;31mTypeError\u001b[0m: Got mixture of dask DataFrames and Arrays. Specify 'convert_mixed_types=True'"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = dms.train_test_split(data, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "This estimator does not support dask dataframes. This might be resolved with one of\n\n    1. ddf.to_dask_array(lengths=True)\n    2. ddf.to_dask_array()  # may cause other issues because of unknown chunk sizes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-59fd495e4127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask_ml\\linear_model\\glm.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobjectj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \"\"\"\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0msolver_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_solver_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask_ml\\linear_model\\glm.py\u001b[0m in \u001b[0;36m_check_array\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_intercept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_unknown_chunks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask_ml\\utils.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_dask_array, accept_dask_dataframe, accept_unknown_chunks, accept_multiple_blocks, preserve_pandas_dataframe, remove_zero_chunks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0maccept_dask_dataframe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             raise TypeError(\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[1;34m\"This estimator does not support dask dataframes. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m                 \u001b[1;34m\"This might be resolved with one of\\n\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;34m\"    1. ddf.to_dask_array(lengths=True)\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: This estimator does not support dask dataframes. This might be resolved with one of\n\n    1. ddf.to_dask_array(lengths=True)\n    2. ddf.to_dask_array()  # may cause other issues because of unknown chunk sizes"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression(fit_intercept=False)\n",
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0], \"max_iter\": [50,100,150,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To fit the data like in usual normal way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = sklearn.model_selection.GridSearchCV(LogisticRegression(),param_grid=param_grid, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "'DataFrame.iloc' only supports selecting columns. It must be used like 'df.iloc[:, column_indexer]'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 600, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 524, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 204, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 393, in _safe_indexing\n    return _pandas_indexing(X, indices, indices_dtype, axis=axis)\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 195, in _pandas_indexing\n    return indexer[:, key] if axis else indexer[key]\n  File \"D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\indexing.py\", line 51, in __getitem__\n    raise NotImplementedError(msg)\nNotImplementedError: 'DataFrame.iloc' only supports selecting columns. It must be used like 'df.iloc[:, column_indexer]'.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    553\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: 'DataFrame.iloc' only supports selecting columns. It must be used like 'df.iloc[:, column_indexer]'."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To fit the data using cluster \n",
    "- Create a Dask client\n",
    "- Use Dask backend to Joblib\n",
    "- Joblib uses context manager\n",
    "- Wrap sklearn code around joblib.parallel_backend('dask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with joblib.parallel_backend('dask'):\n",
    "    joblib.Parallel(verbose=100)\n",
    "    grid_search.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8602187286397812"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8602187286397812"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\SKaul7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0154167 , 0.01041643, 0.0126462 , 0.01563605, 0.03251982,\n",
       "        0.03031031, 0.02413448, 0.02069314, 0.03110806, 0.03380791,\n",
       "        0.0245405 , 0.06569314, 0.04067413, 0.03313351, 0.05947185,\n",
       "        0.03513726, 0.03505707, 0.03489757, 0.03534532, 0.03214065,\n",
       "        0.03918592, 0.04235951, 0.03984634, 0.03919593, 0.03904637,\n",
       "        0.0371863 , 0.04228806, 0.03720005, 0.04461869, 0.04649337,\n",
       "        0.04471914, 0.10466901]),\n",
       " 'std_fit_time': array([2.98961645e-04, 7.36552728e-03, 4.23206416e-03, 1.27701218e-02,\n",
       "        5.37072438e-03, 7.58742268e-03, 4.87956250e-03, 1.13181183e-05,\n",
       "        8.43451996e-03, 1.56026778e-03, 3.35070732e-03, 3.26927783e-02,\n",
       "        1.82574293e-03, 2.72735188e-03, 2.44200718e-02, 5.59229080e-03,\n",
       "        4.53716729e-03, 2.37779792e-03, 7.02319034e-03, 8.11861947e-03,\n",
       "        1.87645324e-03, 8.68121931e-03, 7.66165318e-03, 3.06999561e-03,\n",
       "        4.19017344e-03, 8.70053642e-03, 8.61674038e-03, 4.46860430e-03,\n",
       "        1.13807184e-02, 7.97517596e-03, 9.56792630e-03, 2.45127456e-02]),\n",
       " 'mean_score_time': array([0.00200216, 0.00520833, 0.00222039, 0.        , 0.00256912,\n",
       "        0.00071565, 0.        , 0.00071883, 0.00346041, 0.00272306,\n",
       "        0.00417264, 0.00533517, 0.00071931, 0.00636228, 0.01655483,\n",
       "        0.00271002, 0.00343132, 0.00338872, 0.00889723, 0.00692677,\n",
       "        0.00138227, 0.00272242, 0.0034465 , 0.00272226, 0.        ,\n",
       "        0.00689538, 0.        , 0.00071859, 0.        , 0.00629656,\n",
       "        0.00396371, 0.00133085]),\n",
       " 'std_score_time': array([0.00283148, 0.0073657 , 0.00314011, 0.        , 0.00363328,\n",
       "        0.00101209, 0.        , 0.00101658, 0.00348022, 0.00385099,\n",
       "        0.00446323, 0.00262568, 0.00101726, 0.00465269, 0.01021842,\n",
       "        0.00383255, 0.00343796, 0.00347439, 0.00100984, 0.00489797,\n",
       "        0.00097986, 0.00385009, 0.00346244, 0.00384986, 0.        ,\n",
       "        0.00975154, 0.        , 0.00101624, 0.        , 0.00447533,\n",
       "        0.00322176, 0.00046817]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0,\n",
       "                    1.0, 2.0, 2.0, 2.0, 2.0, 5.0, 5.0, 5.0, 5.0, 10.0,\n",
       "                    10.0, 10.0, 10.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[50, 100, 150, 200, 50, 100, 150, 200, 50, 100, 150,\n",
       "                    200, 50, 100, 150, 200, 50, 100, 150, 200, 50, 100,\n",
       "                    150, 200, 50, 100, 150, 200, 50, 100, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'max_iter': 50},\n",
       "  {'C': 0.001, 'max_iter': 100},\n",
       "  {'C': 0.001, 'max_iter': 150},\n",
       "  {'C': 0.001, 'max_iter': 200},\n",
       "  {'C': 0.01, 'max_iter': 50},\n",
       "  {'C': 0.01, 'max_iter': 100},\n",
       "  {'C': 0.01, 'max_iter': 150},\n",
       "  {'C': 0.01, 'max_iter': 200},\n",
       "  {'C': 0.1, 'max_iter': 50},\n",
       "  {'C': 0.1, 'max_iter': 100},\n",
       "  {'C': 0.1, 'max_iter': 150},\n",
       "  {'C': 0.1, 'max_iter': 200},\n",
       "  {'C': 0.5, 'max_iter': 50},\n",
       "  {'C': 0.5, 'max_iter': 100},\n",
       "  {'C': 0.5, 'max_iter': 150},\n",
       "  {'C': 0.5, 'max_iter': 200},\n",
       "  {'C': 1.0, 'max_iter': 50},\n",
       "  {'C': 1.0, 'max_iter': 100},\n",
       "  {'C': 1.0, 'max_iter': 150},\n",
       "  {'C': 1.0, 'max_iter': 200},\n",
       "  {'C': 2.0, 'max_iter': 50},\n",
       "  {'C': 2.0, 'max_iter': 100},\n",
       "  {'C': 2.0, 'max_iter': 150},\n",
       "  {'C': 2.0, 'max_iter': 200},\n",
       "  {'C': 5.0, 'max_iter': 50},\n",
       "  {'C': 5.0, 'max_iter': 100},\n",
       "  {'C': 5.0, 'max_iter': 150},\n",
       "  {'C': 5.0, 'max_iter': 200},\n",
       "  {'C': 10.0, 'max_iter': 50},\n",
       "  {'C': 10.0, 'max_iter': 100},\n",
       "  {'C': 10.0, 'max_iter': 150},\n",
       "  {'C': 10.0, 'max_iter': 200}],\n",
       " 'split0_test_score': array([0.85143443, 0.85143443, 0.85143443, 0.85143443, 0.85040984,\n",
       "        0.85040984, 0.85040984, 0.85040984, 0.85348361, 0.85348361,\n",
       "        0.85348361, 0.85348361, 0.85860656, 0.85860656, 0.85860656,\n",
       "        0.85860656, 0.86065574, 0.86065574, 0.86065574, 0.86065574,\n",
       "        0.85963115, 0.85963115, 0.85963115, 0.85963115, 0.86065574,\n",
       "        0.86065574, 0.86065574, 0.86065574, 0.86168033, 0.86168033,\n",
       "        0.86168033, 0.86168033]),\n",
       " 'split1_test_score': array([0.85245902, 0.85245902, 0.85245902, 0.85245902, 0.84836066,\n",
       "        0.84836066, 0.84836066, 0.84836066, 0.84836066, 0.84836066,\n",
       "        0.84836066, 0.84836066, 0.85245902, 0.85245902, 0.85245902,\n",
       "        0.85245902, 0.85348361, 0.85348361, 0.85348361, 0.85348361,\n",
       "        0.85860656, 0.85860656, 0.85860656, 0.85860656, 0.85963115,\n",
       "        0.85963115, 0.85963115, 0.85963115, 0.85963115, 0.85963115,\n",
       "        0.85963115, 0.85963115]),\n",
       " 'split2_test_score': array([0.85523614, 0.85523614, 0.85523614, 0.85523614, 0.85318275,\n",
       "        0.85318275, 0.85318275, 0.85318275, 0.85934292, 0.85934292,\n",
       "        0.85934292, 0.85934292, 0.85934292, 0.85934292, 0.85934292,\n",
       "        0.85934292, 0.85831622, 0.85831622, 0.85831622, 0.85831622,\n",
       "        0.85831622, 0.85831622, 0.85831622, 0.85831622, 0.85934292,\n",
       "        0.85934292, 0.85934292, 0.85934292, 0.85934292, 0.85934292,\n",
       "        0.85934292, 0.85934292]),\n",
       " 'mean_test_score': array([0.8530417 , 0.8530417 , 0.8530417 , 0.8530417 , 0.85064935,\n",
       "        0.85064935, 0.85064935, 0.85064935, 0.85372522, 0.85372522,\n",
       "        0.85372522, 0.85372522, 0.85680109, 0.85680109, 0.85680109,\n",
       "        0.85680109, 0.85748462, 0.85748462, 0.85748462, 0.85748462,\n",
       "        0.85885167, 0.85885167, 0.85885167, 0.85885167, 0.85987697,\n",
       "        0.85987697, 0.85987697, 0.85987697, 0.86021873, 0.86021873,\n",
       "        0.86021873, 0.86021873]),\n",
       " 'std_test_score': array([0.0016056 , 0.0016056 , 0.0016056 , 0.0016056 , 0.00197556,\n",
       "        0.00197556, 0.00197556, 0.00197556, 0.00448598, 0.00448598,\n",
       "        0.00448598, 0.00448598, 0.00308656, 0.00308656, 0.00308656,\n",
       "        0.00308656, 0.00298734, 0.00298734, 0.00298734, 0.00298734,\n",
       "        0.00056404, 0.00056404, 0.00056404, 0.00056404, 0.00056338,\n",
       "        0.00056338, 0.00056338, 0.00056338, 0.00104071, 0.00104071,\n",
       "        0.00104071, 0.00104071]),\n",
       " 'rank_test_score': array([25, 25, 25, 25, 29, 29, 29, 29, 21, 21, 21, 21, 17, 17, 17, 17, 13,\n",
       "        13, 13, 13,  9,  9,  9,  9,  5,  5,  5,  5,  1,  1,  1,  1]),\n",
       " 'split0_train_score': array([0.85384615, 0.85384615, 0.85384615, 0.85384615, 0.85384615,\n",
       "        0.85384615, 0.85384615, 0.85384615, 0.85487179, 0.85487179,\n",
       "        0.85487179, 0.85487179, 0.85692308, 0.85692308, 0.85692308,\n",
       "        0.85692308, 0.85846154, 0.85846154, 0.85846154, 0.85846154,\n",
       "        0.85948718, 0.85948718, 0.85948718, 0.85948718, 0.86      ,\n",
       "        0.86      , 0.86      , 0.86      , 0.86      , 0.86      ,\n",
       "        0.86      , 0.86      ]),\n",
       " 'split1_train_score': array([0.85179487, 0.85179487, 0.85179487, 0.85179487, 0.85384615,\n",
       "        0.85384615, 0.85384615, 0.85384615, 0.85538462, 0.85538462,\n",
       "        0.85538462, 0.85538462, 0.8574359 , 0.8574359 , 0.8574359 ,\n",
       "        0.8574359 , 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "        0.85846154, 0.85846154, 0.85846154, 0.85846154, 0.85846154,\n",
       "        0.85846154, 0.85846154, 0.85846154, 0.8574359 , 0.8574359 ,\n",
       "        0.8574359 , 0.8574359 ]),\n",
       " 'split2_train_score': array([0.85348361, 0.85348361, 0.85348361, 0.85348361, 0.85194672,\n",
       "        0.85194672, 0.85194672, 0.85194672, 0.8545082 , 0.8545082 ,\n",
       "        0.8545082 , 0.8545082 , 0.85706967, 0.85706967, 0.85706967,\n",
       "        0.85706967, 0.85706967, 0.85706967, 0.85706967, 0.85706967,\n",
       "        0.85911885, 0.85911885, 0.85911885, 0.85911885, 0.86065574,\n",
       "        0.86065574, 0.86065574, 0.86065574, 0.85911885, 0.85911885,\n",
       "        0.85911885, 0.85911885]),\n",
       " 'mean_train_score': array([0.85304154, 0.85304154, 0.85304154, 0.85304154, 0.85321301,\n",
       "        0.85321301, 0.85321301, 0.85321301, 0.85492154, 0.85492154,\n",
       "        0.85492154, 0.85492154, 0.85714288, 0.85714288, 0.85714288,\n",
       "        0.85714288, 0.85816852, 0.85816852, 0.85816852, 0.85816852,\n",
       "        0.85902252, 0.85902252, 0.85902252, 0.85902252, 0.85970576,\n",
       "        0.85970576, 0.85970576, 0.85970576, 0.85885158, 0.85885158,\n",
       "        0.85885158, 0.85885158]),\n",
       " 'std_train_score': array([0.00089387, 0.00089387, 0.00089387, 0.00089387, 0.0008954 ,\n",
       "        0.0008954 , 0.0008954 , 0.0008954 , 0.00035952, 0.00035952,\n",
       "        0.00035952, 0.00035952, 0.00021566, 0.00021566, 0.00021566,\n",
       "        0.00021566, 0.00080472, 0.00080472, 0.00080472, 0.00080472,\n",
       "        0.00042422, 0.00042422, 0.00042422, 0.00042422, 0.00091962,\n",
       "        0.00091962, 0.00091962, 0.00091962, 0.00106371, 0.00106371,\n",
       "        0.00106371, 0.00106371])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = grid_search.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67138056, 0.32861944],\n",
       "       [0.83166562, 0.16833438],\n",
       "       [0.85282195, 0.14717805],\n",
       "       ...,\n",
       "       [0.88321456, 0.11678544],\n",
       "       [0.82635471, 0.17364529],\n",
       "       [0.92852216, 0.07147784]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[604,   5],\n",
       "       [115,   8]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n          0       0.84      0.99      0.91       609\\n          1       0.62      0.07      0.12       123\\n\\navg / total       0.80      0.84      0.78       732\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_true=ytest, y_pred=ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dask.dataframe' has no attribute 'crosstab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c10a707d255f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Actual Species'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predicted Species'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dask.dataframe' has no attribute 'crosstab'"
     ]
    }
   ],
   "source": [
    "dataframe.crosstab(ytest, ypred, rownames=['Actual Species'], colnames=['Predicted Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperbandSearchCV(clf, params, max_iter=81, random_state=0)\n",
    "\n",
    "search.fit(X_train, y_train, classes=[0, 1]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
